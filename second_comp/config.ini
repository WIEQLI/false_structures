[DATASET]
; Assumption K > a
a = 20
K = 26
eps = 1e-2
delta = 1e-3
add_delta = True
; interval, random, half
data_chooser = interval
draw_dist = beta
; data_size is not in use
data_size = 9000
train_size = 8000
val_size = 500


[TRAIN]
nbr_epochs  = 20000
batch_size = 2500
shuffle = False
optim = adam
;loss = mean_squared_error
loss = sigmoid_cross_entropy
network = functools.partial(simple_net, l_depth=2, l_width=4*K, act=tf.nn.relu)

; These parameters are only used if one choose the gradient decent optimizer is
; chosen
; Gradient decent paramters
start_lr    = 0.00009 
decay_base  = 0.8
decay_every = 500
staircase   = True

[SETUP]
use_gpu      = True
; Compute node is the device number 
; you would like to do computations
compute_node = 0   
dest_model   = models
prec         = tf.float64
counter_path = ./
TF_CPP_MIN_LOG_LEVEL = 2
runner_id = 1
use_run_count = False

[PLOT]
first_comp = True
first_comp_general = True
second_comp = True
second_comp_general = True
f_and_data = True
data_dist = False
training = True
c = 20.5

[TRAIN_SETUP]
ckpt_dir    = ckpt
model_name  = my_model.ckpt
print_every = 500
save_every  = 1*print_every
fsize       = 15



